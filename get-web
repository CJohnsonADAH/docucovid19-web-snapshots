#!/bin/bash

SCRIPT_PATH=$( readlink -f "$0" )
SCRIPT_DIR=$( dirname "${SCRIPT_PATH}" )
SCREENCAP_DIR="${SCRIPT_DIR}/screencaps"
PATH="${SCRIPT_DIR}:${SCREENCAP_DIR}:${PATH}"
SCREENCAP_PID=""

DATA_URL="$1" ; shift
SITE_TAG="$1" ; shift
DATESTAMP="$1" ; shift
DATA_DIR="$1" ; shift
STEP="$1" ; shift
STEPMOD="$1" ; shift
DURATION="$1" ; shift

WG_INCLUDE=""
WG_EXCLUDE="--no-parent"

## Process command-line arguments. This is a bit complicated, because
## many arguments are going to be passed on to wget.

declare -A WG_ARGV=()

WG_ARGV[no-verbose]="--no-verbose"
WG_ARGV[no-check-certificate]="" # off by default; individual sites can turn it on
WG_ARGV[recursive]="--recursive"
WG_ARGV[level]="--level=1"
WG_ARGV[timestamping]="--timestamping"
WG_ARGV[convert-links]="--convert-links"
WG_ARGV[page-requisites]="--page-requisites"
WG_ARGV[backup-converted]="--backup-converted"
WG_ARGV[adjust-extension]="--adjust-extension"
WG_ARGV[restrict-file-names]="--restrict-file-names=windows"
WG_ARGV[timeout]="--timeout=20"
WG_ARGV[tries]="--tries=10"
WG_ARGV[reject_xmlrpc]="--reject=xmlrpc.php"

while [ ! -z "$1" ] ; do
	if [[ "$1" =~ ^--include-directories=(.*) ]] ; then
		WG_INCLUDE="$1"
		if [ "${BASH_REMATCH[1]}" = "-" ] ; then
			WG_INCLUDE=""
			WG_EXCLUDE=""
		elif [ "${BASH_REMATCH[1]}" != "*" ] ; then
			WG_EXCLUDE="--exclude-directories=*"
		else
			WG_INCLUDE=""
			WG_EXCLUDE=""
		fi
	elif [[ "$1" =~ ^--([^=]+)(=.+)? ]] ; then
		WG_ARGV["${BASH_REMATCH[1]}"]="$1"
	fi
	shift
done

if [[ "${DATESTAMP}" == "--first" ]] ; then
	DATESTAMP=""
	STEP=0
	STEPMOD=4
fi

if [ -z "${STEP}" ] ; then
	STEP=0
fi
if [ -z "${STEPMOD}" ] ; then
	STEPMOD=1
fi

POLL_INTERVAL=$( get-all-polling-interval --hours )
DAYSTEPS=$(( 24 / POLL_INTERVAL ))
SITESTEP=$(( STEP % STEPMOD ))
RATIO=$(( STEPMOD / DAYSTEPS ))
if [ "${RATIO}" -eq 0 ] ; then
	RATIO=1
fi
OFFCYCLE=$(( SITESTEP % RATIO ))

if [[ "${DATA_URL}" == "--test" ]] ; then
	printf "DATA_URL: %s\n" "${DATA_URL}"
	printf "SITE_TAG: %s\n" "${SITE_TAG}"
	printf "DATESTAMP: %s\n" "${DATESTAMP}"
	printf "DATA_DIR: %s\n" "${DATA_DIR}"
	printf "STEP: %d\n" "${STEP}"
	printf "STEPMOD: %d\n" "${STEPMOD}"
	printf "DURATION: %d\n" "${DURATION}"
	printf "DAYSTEPS: %d\n" "${DAYSTEPS}"
	printf "SITESTEP: %d\n" "${SITESTEP}"
	printf "RATIO: %d\n" "${RATIO}"
	printf "OFFCYCLE: %d\n" "${OFFCYCLE}"
	exit
fi

if [[ "${OFFCYCLE}" -gt 0 ]] ; then
	TS_TODAY=$( date )
	printf "\n[...] Deferring HTML front page dump of %s (%d-day cycle): %s [...]\n" "${DATA_URL}" "${RATIO}" "${TS_TODAY}"
	exit
fi

if [ -z "${DATA_DIR}" ] ; then
	DATA_DIR="${HOME}/covid-data"
fi
if [ -z "${DATESTAMP}" ] ; then
	DATESTAMP=$( TZ="UTC" date +"%Y%m%d%H%M%SZ" )
fi

HTMLPAGE_DATA="${DATA_DIR}/html"
if [ ! -d "${HTMLPAGE_DATA}/${DATESTAMP}" ] ; then
	mkdir --parents "${HTMLPAGE_DATA}/${DATESTAMP}"
fi

if [ ! -z "${SITE_TAG}" ] ; then
	HTMLPAGE_DATA="${HTMLPAGE_DATA}/${DATESTAMP}/${SITE_TAG}"
fi
HTMLPAGE_DATA="${HTMLPAGE_DATA}-"

export DATA_DIR
export SITE_TAG
export DATESTAMP
export SITESTEP
export WG_INCLUDE
export WG_EXCLUDE
export WG_ARGV
export DATA_URLS
export WARC_SITE_OUT

function do_webarc_mirror () {
	WG_WARC=""
	if [[ "${SITESTEP}" -eq 0 ]] ; then
		WG_WARC="--warc-file=${WARC_SITE_OUT}"
	fi

	cd "${DATA_DIR}"

	MIRROR_DIR="${DATA_DIR}/mirror_${SITE_TAG}"
	if [ ! -d "${MIRROR_DIR}" ] ; then
		mkdir --verbose "${MIRROR_DIR}"
	fi
	cd "${MIRROR_DIR}"

	if [ ! -d "./warc" ] ; then
		mkdir ./warc
	fi
	mv *.warc *.warc.* ./warc

	echo '$' wget  ${WG_INCLUDE} ${WG_EXCLUDE} ${WG_WARC} ${WG_ARGV[@]} "${DATA_URLS[@]}"

	wget ${WG_INCLUDE} ${WG_EXCLUDE} ${WG_WARC} ${WG_ARGV[@]} "${DATA_URLS[@]}"

	if [ ! -z "${WG_WARC}" ] ; then
		if [ -r "${WARC_SITE_OUT}.warc" ] ; then
			get-checksum "${WARC_SITE_OUT}.warc"
		fi
	fi

	#mkdir --verbose "${HTMLPAGE_DATA}${DATESTAMP}.mirror"
	#cd "${HTMLPAGE_DATA}${DATESTAMP}.mirror"

	SNAPSHOTDIR=${DATA_DIR}/html/snapshots/${SITE_TAG}
	if [ ! -d "${SNAPSHOTDIR}" ] ; then
		mkdir --parents "${SNAPSHOTDIR}"
	fi

	cd "${MIRROR_DIR}"
	find -name '*.warc' -exec gzip \{\} \;

	echo '$' make-snapshot.pl "${MIRROR_DIR}/" "${SNAPSHOTDIR}" --timestamp="${DATESTAMP}"
	make-snapshot.pl "${MIRROR_DIR}/" "${SNAPSHOTDIR}" --timestamp="${DATESTAMP}" --exclude=warc
} # /function do_webarc_mirror

# fetch the basic HTML

URL_OUT="${HTMLPAGE_DATA}${DATESTAMP}.url.txt"
DATA_OUT="${HTMLPAGE_DATA}${DATESTAMP}.html"
DATA_PNG="${HTMLPAGE_DATA}${DATESTAMP}.png"
DATA_PNG_N="${HTMLPAGE_DATA}${DATESTAMP}-%d.png"
HEAD_OUT="${HTMLPAGE_DATA}${DATESTAMP}.head"
WARC_OUT="${HTMLPAGE_DATA}${DATESTAMP}"
WARC_SITE_OUT="${SITE_TAG}-${DATESTAMP}"

IFS="|" read -r -a DATA_URLS <<< "${DATA_URL}"
DATA_URL="${DATA_URLS[0]}"
echo "${DATA_URL}" > "${URL_OUT}" 

if [[ ! -z "${WG_ARGV[domains]}" ]] ; then
	WG_ARGV[domains]=$( get-wget-domains-switch "${WG_ARGV[domains]}" "${DATA_URL}" )
fi

wget ${WG_ARGV[no-verbose]} ${WG_ARGV[no-check-certificate]} --output-document="${DATA_OUT}" --warc-file="${WARC_OUT}" "${DATA_URL}"

if [ -r "${DATA_OUT}" ] ; then get-checksum "${DATA_OUT}" ; fi
if [ -r "${WARC_OUT}.warc" ] ; then get-checksum "${WARC_OUT}.warc" ; fi

	LWD="${PWD}"
	cd "${SCREENCAP_DIR}"
	IDX=0
	for URL in "${DATA_URLS[@]}" ; do
		OUT_PNG="${DATA_PNG}"
		if [ "${IDX}" -gt 0 ] ; then
			wait "${SCREENCAP_PID}"
			echo "... Screencap completed."

			OUT_PNG=$( printf "${DATA_PNG_N}" "${IDX}" )
		fi
		node --unhandled-rejections=strict ./screencap.js --headless "${URL}" "${OUT_PNG}" "${DURATION}" & # this can take a while, do it in the background
		SCREENCAP_PID="$!"

		IDX=$((IDX + 1))
	done
	cd "${LWD}"

# mirror the site
do_webarc_mirror

if [[ ! -z "${SCREENCAP_PID}" && -r "/proc/${SCREENCAP_PID}" ]] ; then
	wait "${SCREENCAP_PID}"
	echo "... Screencap completed."
fi

echo "Completed HTML front page dump of ${DATA_URL}: " $( date )

