#!/bin/bash
#
# get-all: Script to orchestrate scheduled or on-demand web archiving and
# data-table archiving.
#
# Usage: get-all [--sync] [--data] [--web] [slug...]
#
# @version 2020.0429

export SCRIPT_PATH=$( readlink -f "$0" )
export SCRIPT_DIR=$( dirname "${SCRIPT_PATH}" )
export PATH="${SCRIPT_DIR}:${PATH}"
export NODE_NAME=$( uname --node )

export DATA_SERVER="alacovdat.dev.radgeek.net"
export DATA_SLUG="covid-data"
export DATA_DIR=$( readlink -f "${HOME}/${DATA_SLUG}" )

if [[ ! -d "${DATA_DIR}" ]] ; then
	mkdir --parents --verbose "${DATA_DIR}"
fi
cd "${DATA_DIR}"

declare -a GA_ARGV=("$0")
declare -a GA_OBJS=()
declare -A GA_SWITCHES=()
declare -A GA_PARAMS=()

while [ $# -gt 0 ] ; do
	GA_ARGV=("${GA_ARGV[@]}" "$1")
	if [[ "$1" =~ ^--([^=]+)(=(.*))?$ ]] ; then
		KEY="${BASH_REMATCH[1]}"
		GA_SWITCHES["${KEY}"]="${BASH_REMATCH[0]}"
		GA_PARAMS["${KEY}"]="${KEY}"
		if [ ! -z "${BASH_REMATCH[2]}" ] ; then
			GA_PARAMS["${KEY}"]="${BASH_REMATCH[3]}"
		fi
	else
		GA_OBJS=("${GA_OBJS[@]}" "$1")
	fi
	shift
done

if [ "${GA_PARAMS[test]}" = "argv" ] ; then
	declare -p GA_ARGV
	declare -p GA_OBJS
	declare -p GA_SWITCHES
	declare -p GA_PARAMS
	exit
fi

# Defaults
SYNC=0
DATAONLY=0
WEBONLY=0

POLL_INTERVAL=$( get-all-polling-interval --hours )

if [[ "${GA_PARAMS[sync]}" == "sync" ]] ; then
	SYNC=1
fi

if [[ "${GA_PARAMS[data]}" == "data" ]] ; then
	DATAONLY=1
fi

if [[ "${GA_PARAMS[web]}" == "web" ]] ; then
	WEBONLY=1
fi

if [[ ( "${WEBONLY}" -eq 1 ) && ( "${DATAONLY}" -eq 1 ) ]] ; then
	DATAONLY=0
	WEBONLY=0
fi

FILTER_SLUG=""
for SLUG in "${GA_OBJS[@]}" ; do
	if [ ! -z "${SLUG}" ] ; then
		if [ ! -z "${FILTER_SLUG}" ] ; then
			FILTER_SLUG="${FILTER_SLUG}|"
		fi
		FILTER_SLUG="${FILTER_SLUG}${SLUG}"
	fi
done

if [ ! -z "${FILTER_SLUG}" ] ; then
	FILTER_SLUG="(${FILTER_SLUG})"
fi

if [ "${GA_PARAMS[test]}" = "parameters" ] ; then
	printf "POLL INTERVAL: %d\n" "${POLL_INTERVAL}"
	printf "SYNC: %d\n" "${SYNC}"
	printf "WEBONLY: %d\n" "${WEBONLY}"
	printf "DATAONLY: %d\n" "${DATAONLY}"
	printf "FILTER SLUG: %s\n" "${FILTER_SLUG}"
	exit
fi

if [ "${SYNC}" -ne 0 ] ; then
	echo "=== Sync: Preparing for Transmit ==="
	echo '$' find "${DATA_DIR}" -maxdepth 4 -name '*.warc' -exec gzip --verbose \{\} \;
	find "${DATA_DIR}" -maxdepth 4 -name '*.warc' -exec gzip --verbose \{\} \;

	echo "... transmitting via rsync ..."
	if [ "${DATAONLY}" -eq 0 ] ; then
		if [ "${WEBONLY}" -eq 0 ] ; then
			rsync --archive --itemize-changes --progress --exclude="mirror_*" --hard-links --exclude="${DATA_SERVER}" --exclude="get-all.log" ./ ${DATA_SERVER}:${DATA_SLUG}/
		else
			rsync --archive --itemize-changes --progress --hard-links --exclude="get-all.log" ./html/ ${DATA_SERVER}:${DATA_SLUG}/html/
		fi
	else
		rsync --archive --itemize-changes --progress --exclude="mirror_*" --exclude="get-all.log" --hard-links ./data/ ${DATA_SERVER}:${DATA_SLUG}/data/

	fi
	exit
fi

if [[ "${DATAONLY}" -eq 0 ]] ; then
	if [[ -z "${FILTER_SLUG}" ]] ; then
		STEP_FILE="${DATA_DIR}/snapshot-step.txt"

		if [ -r "${STEP_FILE}" ] ; then
			STEP=$( cat "${DATA_DIR}/snapshot-step.txt" )
		else
			STEP=3
		fi
		STEP=$(( (STEP + 1) ))
		if [[ "${GA_PARAMS[dry-run]}" != "dry-run" ]] ; then
			printf "%d\n" "${STEP}" > "${STEP_FILE}"
		fi

		printf "*** Web Site Poll # %d ***\n" "${STEP}"
	fi
fi

DATESTAMP=$( TZ="UTC" date +"%Y%m%d%H%M%SZ" )

if [[ "${WEBONLY}" -eq 0 ]] ; then

	printf "=== Capturing Data Sets ===\n"
	DATA_SOURCES="data-sources.tsv.txt"
	DATA_SOURCES_URL="${DATA_SERVER}/${DATA_SOURCES}"

wget --no-verbose --mirror "http://${DATA_SOURCES_URL}"
while IFS="" read LINE; do
	DATA_TYPE=$( printf "%s" "$LINE" | cut -f 1 )
	DATA_SLUG=$( printf "%s" "$LINE" | cut -f 2 )
	DATA_PATH=$( printf "%s" "$LINE" | cut -f 3 )
	DATA_PARAM=$( printf "%s" "$LINE" | cut -f 4 )

	if [ ! -z "${DATA_PATH}" ] ; then
		DATA_URL="${DATA_PATH}"
		if [ ! -z "${DATA_PARAM}" ] ; then
			DATA_URL="${DATA_URL}?f=json&${DATA_PARAM}"
		fi
		
		GET_DATA="noop"
		if [[ "${DATA_SLUG}" =~ ${FILTER_SLUG} ]] ; then
			if [[ "${GA_PARAMS[dry-run]}" != "dry-run" ]] ; then
				GET_DATA="get-data"
			fi
			printf "\n"
			echo '$' ${GET_DATA} "${DATA_URL}" "${DATA_SLUG}" "${DATESTAMP}" "${DATA_DIR}"
		fi

		${GET_DATA} "${DATA_URL}" "${DATA_SLUG}" "${DATESTAMP}" "${DATA_DIR}" "${DATA_TYPE}"

	fi
done < "${DATA_DIR}/${DATA_SOURCES_URL}"


fi

if [[ "${DATAONLY}" -eq 0 ]] ; then

	printf "\n=== Capturing Web Sites ===\n"

	OFFSET=0

wget --no-verbose --mirror "http://${DATA_SERVER}/sources.tsv.txt"
while IFS="" read LINE; do
	RE="--regexp-extended"

	if [[ "${LINE}" =~ ([#][@]([A-Za-z0-9]+)) ]] ; then
		FOR_NODE="${BASH_REMATCH[2]}"
	else
		FOR_NODE="${NODE_NAME}"
	fi

	# remove comments and trim
	LINE=$(
		printf "%s" "${LINE}" \
		| sed ${RE} 's/(^|\s)[#].*$//' \
		| sed ${RE} 's/^\s+//' \
		| sed ${RE} 's/\s+$//'
	)
	
	if [ -z "${LINE}" ] ; then
		continue
	fi

	WWW_CYCLE=$( printf "%s" "$LINE" | cut -f 1 )
	WWW_PERIOD=$(( WWW_CYCLE / POLL_INTERVAL ))
	WWW_DURATION=$( printf "%s" "$LINE" | cut -f 2 )
	WWW_SLUG=$( printf "%s" "$LINE" | cut -f 3 )
	WWW_URL=$( printf "%s" "$LINE" | cut -f 4 )

	declare -a WWW_SWITCHES=()
	FIELD=5
	WWW_SWITCH="dummy"
	while [ ! -z "${WWW_SWITCH}" ] ; do
		WWW_SWITCH=$( printf "%s" "$LINE" | cut -f "${FIELD}" )
		if [ ! -z "${WWW_SWITCH}" ] ; then
			WWW_SWITCHES=("${WWW_SWITCHES[@]}" "${WWW_SWITCH}")
		fi
		FIELD=$((FIELD+1))
	done

	if [ ! -z "${WWW_URL}" ] ; then
		if [[ -z "${FILTER_SLUG}" ]] ; then
			SITESTEP=$(( STEP + OFFSET ))
		else
			SITESTEP=$(( STEP ))
		fi

		GET_WEB="noop"
		if [[ "${WWW_SLUG}" =~ ${FILTER_SLUG} ]] ; then
			if [[ "${GA_PARAMS[dry-run]}" != "dry-run" ]] ; then
				GET_WEB="get-web"
			fi
			printf "\n"
			echo '$' ${GET_WEB} "${WWW_URL}" "${WWW_SLUG}" "${DATESTAMP}" "${DATA_DIR}" "${SITESTEP}" "${WWW_PERIOD}" "${WWW_DURATION}" ${WWW_SWITCHES[@]}
		fi

		${GET_WEB} "${WWW_URL}" "${WWW_SLUG}" "${DATESTAMP}" "${DATA_DIR}" "${SITESTEP}" "${WWW_PERIOD}" "${WWW_DURATION}" ${WWW_SWITCHES[@]}

	fi

	unset WWW_SWITCHES
	OFFSET=$(( OFFSET + 1 ))
done < "${DATA_DIR}/${DATA_SERVER}/sources.tsv.txt"

echo "[==] Completed web snapshots: " $( date ) " [==]"

fi

exit

